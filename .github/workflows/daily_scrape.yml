name: Daily Scrape & Deploy

on:
  schedule:
    - cron: '0 13 * * *' # 每天 ET 08:00 运行
  workflow_dispatch:      # 允许手动触发

# ⚠️ 关键：赋予所有权限，既能提交代码，也能发布网页
permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    concurrency:
      group: "pages"
      cancel-in-progress: false
    
    steps:
      # --- 第一阶段：环境准备 ---
      - name: Checkout code
        uses: actions/checkout@v4

      # --- 第二阶段：运行 Python 爬虫 ---
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Python dependencies
        run: pip install requests

      - name: Run Scraper
        env:
          RAPIDAPI_KEY: ${{ secrets.RAPIDAPI_KEY }}
        run: python scraper.py

      # --- 第三阶段：提交数据 (可选，方便你在仓库里看历史) ---
      - name: Commit new jobs.json
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add public/jobs.json
          # 如果有变化就提交，没变化就不提交，但继续往下走
          git diff --staged --quiet || (git commit -m "chore: daily data update" && git push)

      # --- 第四阶段：构建 React 网站 ---
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install Node dependencies
        run: npm ci

      - name: Build Project
        run: npm run build

      # --- 第五阶段：发布到 GitHub Pages ---
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./dist

      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v4