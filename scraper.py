import requests
import json
import os
from datetime import datetime

# ==========================================
# 1. é…ç½®ä¸å¯†é’¥ (Configuration)
# ==========================================

api_key = os.environ.get("RAPIDAPI_KEY")

# ğŸš¨ æœ¬åœ°æµ‹è¯•æ—¶æ‰“å¼€è¿™è¡Œï¼Œæäº¤å‰æ³¨é‡Šæ‰ï¼
# api_key = "ä½ çš„_RAPIDAPI_KEY"

if not api_key:
    print("âŒ Error: RAPIDAPI_KEY is missing.")
    exit(1)

url = "https://jsearch.p.rapidapi.com/search"

# ==========================================
# 2. æœç´¢ç­–ç•¥ (ä»ä½ çš„åˆ—è¡¨ä¸­æå–çš„æ ¸å¿ƒå…³é”®è¯)
# ==========================================

# æˆ‘ä»ä½ æä¾›çš„ 100+ ä¸ªèŒä½ä¸­æå–äº†ä»¥ä¸‹æ ¸å¿ƒé«˜é¢‘è¯ï¼Œå¹¶ç”¨ OR è¿æ¥
# è¿™æ ·ä¸€æ¬¡ API è°ƒç”¨å°±èƒ½è¦†ç›–æ‰€æœ‰è¿™äº›ç»†åˆ†é¢†åŸŸï¼Œæåº¦èŠ‚çœé¢åº¦ã€‚

search_term = """
(
"People Analyst" OR "HR Data Analyst" OR "People Data Analyst" OR 
"Workforce Analytics" OR "Workforce Planning Analyst" OR 
"HRIS Analyst" OR "HR Systems Analyst" OR "HR Tech Analyst" OR "Workday Analyst" OR 
"Compensation Analyst" OR "Total Rewards Analyst" OR 
"Talent Analytics" OR "Talent Insights" OR "Recruiting Data Analyst" OR 
"People Operations Analyst" OR "Employee Experience Analyst"
)
"""

# å»æ‰æ¢è¡Œç¬¦ï¼Œå˜æˆä¸€è¡Œ
search_term = search_term.replace('\n', ' ').strip()

querystring = {
    # æ ¸å¿ƒé€»è¾‘ï¼š(æ ¸å¿ƒèŒä½) AND (åœ¨ç¾å›½ OR åŠ æ‹¿å¤§) AND (è¿œç¨‹ OR æ··åˆ)
    "query": f"{search_term} in USA OR Canada (Remote OR Hybrid)", 
    "page": "1",
    "num_pages": "10", 
    "date_posted": "3days",   
    "employment_types": "fulltime" 
}

headers = {
    "X-RapidAPI-Key": api_key,
    "X-RapidAPI-Host": "jsearch.p.rapidapi.com"
}

# ==========================================
# 3. æ‰§è¡ŒæŠ“å–ä¸æ¸…æ´—
# ==========================================

try:
    print(f"ğŸ” Fetching jobs...")
    response = requests.get(url, headers=headers, params=querystring)
    response.raise_for_status()
    
    data = response.json()
    raw_jobs = data.get('data', [])
    print(f"ğŸ“¦ API returned {len(raw_jobs)} raw jobs.")

    clean_jobs = []
    
    # åƒåœ¾è¯é»‘åå• (æ ¹æ®ä½ çš„åˆ—è¡¨ä¼˜åŒ–ï¼Œæ’é™¤æ‰çº¯ Recruiting æˆ– Sales å²—)
    exclude_keywords = [
        "recruiter", "talent acquisition partner", "coordinator", "assistant", 
        "intern", "sales", "account executive", "business development"
    ]

    for job in raw_jobs:
        title = job.get("job_title", "").lower()
        
        # 1. åƒåœ¾è¯è¿‡æ»¤
        if any(keyword in title for keyword in exclude_keywords):
            continue 
            
        # 2. ID æ ¡éªŒ
        job_id = job.get("job_id") or job.get("job_apply_link")
        
        if job_id: 
            clean_jobs.append({
                "job_id": job_id,
                "job_title": job.get("job_title"),
                "employer_name": job.get("employer_name"),
                "employer_logo": job.get("employer_logo"),
                "job_city": job.get("job_city"),
                "job_state": job.get("job_state"),
                "job_country": job.get("job_country"),
                "job_apply_link": job.get("job_apply_link"),
                "job_posted_at_datetime_utc": job.get("job_posted_at_datetime_utc")
            })

    # ==========================================
    # 4. ä¿å­˜æ•°æ®
    # ==========================================

    final_data = {
        "last_updated": datetime.utcnow().isoformat(),
        "total_jobs": len(clean_jobs),
        "jobs": clean_jobs
    }

    os.makedirs('public', exist_ok=True)
    
    with open('public/jobs.json', 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Success! Saved {len(clean_jobs)} clean jobs to public/jobs.json")

except Exception as e:
    print(f"âŒ Error occurred: {e}")
    exit(1)